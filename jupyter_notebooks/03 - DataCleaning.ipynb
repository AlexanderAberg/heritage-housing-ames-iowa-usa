{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# Data Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "*   Evaluate missing data\n",
    "*   Clean data\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n",
    "\n",
    "## Conclusions\n",
    "\n",
    " \n",
    "  * Data Cleaning Pipeline\n",
    "  * Drop Variables:  `['GarageFinish', 'WoodDeckSF', 'KitchenQual', 'EnclosedPorch' ]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kspgyffxear-"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/heritage-housing-ames-iowa-usa/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/heritage-housing-ames-iowa-usa'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tdAGw4Zwssu"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Load Collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2ELZj83tF1g",
    "outputId": "d51e2567-7f6c-4200-b9c2-d4982d22e6fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0            2         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "\n",
       "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
       "0        150            0.0         548          RFn  ...         65.0   \n",
       "1        284            NaN         460          RFn  ...         80.0   \n",
       "2        434            0.0         608          RFn  ...         68.0   \n",
       "\n",
       "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0       196.0          61            5            7          856         0.0   \n",
       "1         0.0           0            8            6         1262         NaN   \n",
       "2       162.0          42            5            7          920         NaN   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       2003          2003     208500  \n",
       "1       1976          1976     181500  \n",
       "2       2001          2002     223500  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_raw_path = \"outputs/datasets/collection/TelcoCustomerChurn.csv\"\n",
    "df = pd.read_csv(df_raw_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iue5e5GJ_vZg"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhWelcb_17dw"
   },
   "source": [
    "In Data Cleaning you are interested to check the distribution and shape of a variable with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2ndFlrSF',\n",
       " 'BedroomAbvGr',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'EnclosedPorch',\n",
       " 'GarageFinish',\n",
       " 'GarageYrBlt',\n",
       " 'LotFrontage',\n",
       " 'MasVnrArea',\n",
       " 'WoodDeckSF']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oyi3gi2-_q1j"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ydata_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vars_with_missing_data:\n\u001b[1;32m      3\u001b[0m     profile \u001b[38;5;241m=\u001b[39m ProfileReport(df\u001b[38;5;241m=\u001b[39mdf[vars_with_missing_data], minimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ydata_profiling'"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "if vars_with_missing_data:\n",
    "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "    profile.to_notebook_iframe()\n",
    "else:\n",
    "    print(\"There are no variables with missing data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvwabO0JsmYW"
   },
   "source": [
    "# Correlation and PPS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g6Zy_MglsmYo"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mppscore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpps\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                    linewidth=0.5\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                         linewidth=0.05, linecolor='grey')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "    df_corr_spearman = df.corr(method=\"spearman\", numeric_only=True)\n",
    "    df_corr_pearson = df.corr(method=\"pearson\", numeric_only=True)\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "    print(pps_score_stats.round(3))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(20, 12), font_annot=8):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "    print(\"It evaluates monotonic relationship \\n\")\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
    "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryNo1VnXSK9K"
   },
   "source": [
    "Calculate Correlations and Power Predictive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_Z4SXf6GbED",
    "outputId": "6978dbde-ebb0-4023-af6c-b6f896ced798"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CalculateCorrAndPPS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_corr_pearson, df_corr_spearman, pps_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mCalculateCorrAndPPS\u001b[49m(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CalculateCorrAndPPS' is not defined"
     ]
    }
   ],
   "source": [
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ-0L4PiSPEK"
   },
   "source": [
    "Display at Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ioE3yuC4Q7QK",
    "outputId": "1946ffa1-2e5d-4972-eeda-45d7fe382314"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DisplayCorrAndPPS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDisplayCorrAndPPS\u001b[49m(df_corr_pearson \u001b[38;5;241m=\u001b[39m df_corr_pearson,\n\u001b[1;32m      2\u001b[0m                   df_corr_spearman \u001b[38;5;241m=\u001b[39m df_corr_spearman, \n\u001b[1;32m      3\u001b[0m                   pps_matrix \u001b[38;5;241m=\u001b[39m pps_matrix,\n\u001b[1;32m      4\u001b[0m                   CorrThreshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m, PPS_Threshold \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      5\u001b[0m                   figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m10\u001b[39m), font_annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DisplayCorrAndPPS' is not defined"
     ]
    }
   ],
   "source": [
    "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
    "                  df_corr_spearman = df_corr_spearman, \n",
    "                  pps_matrix = pps_matrix,\n",
    "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
    "                  figsize=(12,10), font_annot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYdZHyDhu4kG"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxoVRefhu2Bk"
   },
   "source": [
    "## Assessing Missing Data Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcocWZkIx6nk"
   },
   "source": [
    "* Custom function to display missing data levels in a DataFrame, it shows the absolute levels, relative levels and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "z9CoLqBhO7ga"
   },
   "outputs": [],
   "source": [
    "def EvaluateMissingData(df):\n",
    "    missing_data_absolute = df.isnull().sum()\n",
    "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
    "    df_missing_data = (pd.DataFrame(\n",
    "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
    "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
    "                                   \"DataType\": df.dtypes}\n",
    "                                    )\n",
    "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
    "                          .query(\"PercentageOfDataset > 0\")\n",
    "                          )\n",
    "\n",
    "    return df_missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHrzaG-ZhEKt"
   },
   "source": [
    "Check missing data levels for the collected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "zxvNnLAjxCSi",
    "outputId": "e6239998-21e1-4401-80de-e25c33bbba52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowsWithMissingData</th>\n",
       "      <th>PercentageOfDataset</th>\n",
       "      <th>DataType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>1324</td>\n",
       "      <td>90.68</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>1305</td>\n",
       "      <td>89.38</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.74</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>235</td>\n",
       "      <td>16.10</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>145</td>\n",
       "      <td>9.93</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>99</td>\n",
       "      <td>6.78</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>86</td>\n",
       "      <td>5.89</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.55</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.60</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.55</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RowsWithMissingData  PercentageOfDataset DataType\n",
       "EnclosedPorch                 1324                90.68  float64\n",
       "WoodDeckSF                    1305                89.38  float64\n",
       "LotFrontage                    259                17.74  float64\n",
       "GarageFinish                   235                16.10   object\n",
       "BsmtFinType1                   145                 9.93   object\n",
       "BedroomAbvGr                    99                 6.78  float64\n",
       "2ndFlrSF                        86                 5.89  float64\n",
       "GarageYrBlt                     81                 5.55  float64\n",
       "BsmtExposure                    38                 2.60   object\n",
       "MasVnrArea                       8                 0.55  float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateMissingData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWAI2EAp2FNM"
   },
   "source": [
    "## Data Cleaning Spreadsheet Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp-lSdVH-_-3"
   },
   "source": [
    "* Consider your spreadsheet notes on potential approaches to handle missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsL8yYQEyOSt"
   },
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset doesn't require much data cleaning, therefore we are not loading the DataCleaningEffect() function we studied in the feature-engine lesson.\n",
    "* For your future projects, this would be a moment to load that function and use it over your data-cleaning process.\n",
    "* For this project, we are skipping this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt8Yqjy6ghyw"
   },
   "source": [
    "### Data Cleaning Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4GaYe_DgqwT"
   },
   "source": [
    "List here the data cleaning approaches you want initially to try.\n",
    "* Drop - `['customerID', 'TotalCharges' ]`\n",
    "\n",
    "\n",
    "**The list above is your guide, your map to know at which stage you are in the data-cleaning process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W12Z8KIPoZ-8"
   },
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Knk7DcVborLI",
    "outputId": "049ef5f2-c431-4a9d-fd87-00809986c38d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      2\u001b[0m TrainSet, TestSet, _, __ \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      3\u001b[0m                                         df,\n\u001b[1;32m      4\u001b[0m                                         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePRice\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                         test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainSet shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTrainSet\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTestSet shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTestSet\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TrainSet, TestSet, _, __ = train_test_split(\n",
    "                                        df,\n",
    "                                        df['SalePRice'],\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0)\n",
    "\n",
    "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "zdMPKBU_yCpF",
    "outputId": "df45adaf-5e93-4644-919f-6b82e51fe8b7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_missing_data \u001b[38;5;241m=\u001b[39m EvaluateMissingData(\u001b[43mTrainSet\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m* There are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_missing_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m variables with missing data \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_missing_data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainSet' is not defined"
     ]
    }
   ],
   "source": [
    "df_missing_data = EvaluateMissingData(TrainSet)\n",
    "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
    "df_missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUeGUUmu4qru"
   },
   "source": [
    "### Drop Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLTFTio14qr8"
   },
   "source": [
    "* Hint: you may drop Variables with more than 80% of missing data since these variables will likely not add much value. However, this is not the case in this dataset\n",
    "* Step 1: imputation approach: **Drop Variables**\n",
    "* Step 2: Select variables to apply the imputation approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlQBeLo44qr8",
    "outputId": "6a342431-6be3-48fa-ce83-ed00489d960c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 4 variables to drop \n",
      "\n",
      "['GarageFinish', 'WoodDeckSF', 'KitchenQual', 'EnclosedPorch']\n"
     ]
    }
   ],
   "source": [
    "variables_method = ['GarageFinish',\n",
    "                    'WoodDeckSF', 'KitchenQual', 'EnclosedPorch']\n",
    "\n",
    "print(f\"* {len(variables_method)} variables to drop \\n\\n\"\n",
    "    f\"{variables_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1kKajldGrqF"
   },
   "source": [
    "* We are dropping `CustomerID` since it is a unique identifier for each customer, it doesn't add information to the dataset as it is.\n",
    "* We are dropping `TotalCharges` as for the context of the ML projects, a prospect doesn't have `TotalCharges`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7au_UdA34qr9"
   },
   "source": [
    "* Step 3: Create a separate DataFrame applying this imputation approach to the selected variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Zh9E2cEe4qr9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feature_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DropFeatures\n\u001b[1;32m      2\u001b[0m imputer \u001b[38;5;241m=\u001b[39m DropFeatures(features_to_drop\u001b[38;5;241m=\u001b[39mvariables_method)\n\u001b[1;32m      3\u001b[0m imputer\u001b[38;5;241m.\u001b[39mfit(TrainSet)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'feature_engine'"
     ]
    }
   ],
   "source": [
    "from feature_engine.selection import DropFeatures\n",
    "imputer = DropFeatures(features_to_drop=variables_method)\n",
    "imputer.fit(TrainSet)\n",
    "df_method = imputer.transform(TrainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsjRXMlU4qr9"
   },
   "source": [
    "* Step 4: Assess the effect on the variable's distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc9pg4ww_BO-"
   },
   "source": [
    "* In this case, there is no effect on the distribution of the variable, since you are not removing rows, but columns.\n",
    "* The effect might be losing features that might have a relevant impact on your machine-learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBq1a_Me4qr-"
   },
   "source": [
    "* Step 5: If you are satisfied, apply the transformation to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NGO5M1k44qr-"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feature_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DropFeatures\n\u001b[1;32m      2\u001b[0m imputer \u001b[38;5;241m=\u001b[39m DropFeatures(features_to_drop\u001b[38;5;241m=\u001b[39mvariables_method)\n\u001b[1;32m      3\u001b[0m imputer\u001b[38;5;241m.\u001b[39mfit(TrainSet)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'feature_engine'"
     ]
    }
   ],
   "source": [
    "from feature_engine.selection import DropFeatures\n",
    "imputer = DropFeatures(features_to_drop=variables_method)\n",
    "imputer.fit(TrainSet)\n",
    "\n",
    "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LozxNCVO4qr_"
   },
   "source": [
    "* Step 6: Evaluate if you have more variables to deal with. If yes, iterate. If not, you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "zGmZy46L4qr_",
    "outputId": "3597364f-19a3-42af-8d56-3bbcfe8675e4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m EvaluateMissingData(\u001b[43mTrainSet\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainSet' is not defined"
     ]
    }
   ],
   "source": [
    "EvaluateMissingData(TrainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD--GI5Jvp8h"
   },
   "source": [
    "# Push cleaned data to Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1SNWONrYwu6d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
    "except Exception as e:\n",
    "  print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE3DQfy82r7I"
   },
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q1ayKT4F2p52"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTrainSet\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/datasets/cleaned/TrainSetCleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainSet' is not defined"
     ]
    }
   ],
   "source": [
    "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTTabVk-2ulD"
   },
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zCjorYny2qCD"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TestSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTestSet\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/datasets/cleaned/TestSetCleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TestSet' is not defined"
     ]
    }
   ],
   "source": [
    "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! Clear cell outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgNVNpuV6NV2"
   },
   "source": [
    "Well done! You can now push the changes to your GitHub Repo, using the Git commands (git add, git commit, git push)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
